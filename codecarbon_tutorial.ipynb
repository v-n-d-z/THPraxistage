{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Energy Benchmarking of Deep Learning Workflows**\n",
    "\n",
    "### **1.) Introduction to Energy Benchmarking with CodeCarbon**\n",
    "\n",
    "Researchers in the domains of Green AI or AI Efficiency have recenty started to include \"Energy Fact Sheets\" of the proposed models in their papers, similar to how the nutritional fact sheet on food items lists what is in the food you eat.\n",
    "\n",
    "This makes it possible for others to compare and grasp what kind of resources the researchers had at their disposal (GPUs, TPUs, ...), how many parameters their models have (Amount and FLOPs), how much energy was needed for a single training iteration or a single inference call, and sometimes also how many re-training attempts they did in total during their development.\n",
    "\n",
    "If direct hardware-based measuring of the energy usage is not possible or to much of an effort, software tools such as ***CodeCarbon*** are a good alternative, although generally less accurate. \n",
    "\n",
    "***CodeCarbon*** allows you to track the energy usage of your code with an intuitive *wrapping mechanism*. You can either use the explicit `EmissionsTracker` tracker object and wrap the code you want to benchmark with the `tracker.start()` and `tracker.stop()` functions. Or, if you already have your code bundled into individual functions, you can make use of the built-in function decorator `@track_emissions`.\n",
    "\n",
    "Both versions do the same things: \n",
    "1. Keep track of the starting time when you call `tracker.start()` or the decorated function\n",
    "2. Get an initial measurement of the energy usage at the start\n",
    "3. Start a scheduler in the background that does a measurement every X seconds while your code runs\n",
    "4. Wait until you either stop the tracking with `tracker.stop()` or the decorated function terminates\n",
    "5. Do another meaurement at the end\n",
    "6. Collect and aggregate the measurment data for you *(and store or return it to you depending on how you configured it)*\n",
    "\n",
    "\n",
    "#### **The following two ways are examples of how you can use this in your code:**\n",
    "##### **Version 1 - Tracker object**\n",
    "```python\n",
    "    from codecarbon import EmissionsTracker\n",
    "    \n",
    "    tracker = EmissionsTracker(\n",
    "        #... configurations\n",
    "    )\n",
    "\n",
    "    tracker.start()\n",
    "    try:\n",
    "        # ... do something   \n",
    "    finally:\n",
    "        tracker.stop()\n",
    "    \n",
    "    results = tracker.final_emissions_data\n",
    "```\n",
    "\n",
    "\n",
    "##### **Version 2 - Function decorator**\n",
    "\n",
    "```python\n",
    "    from codecarbon import track_emissions\n",
    "\n",
    "    @track_emissions(\n",
    "        #... configurations\n",
    "    )\n",
    "    def func()\n",
    "        # ... do something\n",
    "```\n",
    "\n",
    "To access the energy benchmark data, you can either look into the `.csv` file that is created by default. Every row corresponds to one call of `start()` to `stop()`. Alternatively, and more useful if you want to directly do something with the respective value, you can access the `final_emissions_data` attribute of the tracker object (This of course only works if you explicitly use the tracker object and not the function decorator).\n",
    "\n",
    "### **2.) Energy Benchmarking of Model Training and Testing**\n",
    "\n",
    "Understanding the energy usage of AI models is important for the reduction of the immense carbon footprint of modern AI and making AI development, in general, more sustainable. \n",
    "\n",
    "For this next part of the notebook, we will train deep learning models on the Oxford IIIT Pets dataset (see [here](https://pytorch.org/vision/stable/generated/torchvision.datasets.OxfordIIITPet.html) and [here](https://www.robots.ox.ac.uk/~vgg/data/pets/)). Your task is to train a deep learning model, achieve an accuracy of at least 80% and find ways to make the training phase of the model as energy efficient as possible.\n",
    "\n",
    "We will start by implementing the two helper functions `train_model()` and `test_model()`. These should make it easier and faster for you to go over multiple iterations of your models and try different approaches. Once the basic functionality is implemented, you can extend them how ever you please.\n",
    "\n",
    "#### **Getting Started**\n",
    "\n",
    "1. Set up your virtual environment for python and run the import cell down below\n",
    "2. Implement the leftout spaces of the train_model function\n",
    "3. Implement a basic first model to test and familiarize yourself with how the two functions work (also helps to get a baseline for the accuracy and energy usage)\n",
    "4. Extend your models and the two functions to increase the energy efficiency \n",
    "    - have a look at ***Things you can consider*** down below to get some ideas where to start.\n",
    "    - have a look at the basic implementation of the `test_model()` function to get an understanding of what we expect from you in the `train_model()` function that you have to implement yourself.\n",
    "\n",
    "**Things you can consider:**\n",
    "\n",
    "- Run model on CPU vs. GPU (see [here](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html) and [here](https://pytorch.org/docs/stable/tensor_attributes.html#torch.device))\n",
    "- Model architecture and size ([custom models](https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html) vs. [built-in Pytorch models](https://pytorch.org/vision/stable/models.html))\n",
    "- Pretrained model weights vs. starting from scratch\n",
    "- Different optimizers (see [here](https://pytorch.org/docs/stable/optim.html))\n",
    "- Learning rate and adaptation strategies (Warm-start, Decay, ...)\n",
    "- Batch size\n",
    "- Data augmentation (see [here](https://pytorch.org/vision/stable/transforms.html))\n",
    "- Different loss functions\n",
    "- Train/Test vs. Train/Validation/Test split of the data set. What could a additional validation set be useful for? (*Hint: Early Stopping*)\n",
    "\n",
    "Due to the limited time you have, do not worry about implementing or trying out all of these examples. Start by discussing with your colleagues which of these examples help the model to be more energy efficient, and if so, how they achieve it.\n",
    "\n",
    "Afterwards, pick and focus on the few that you think would help the most (or that you simply find the most interesting to implement). You are, of course, also allowed to come up with your own strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies, you can add whatever additional things you want to use\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from codecarbon import EmissionsTracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `train_model()` function\n",
    "This function should take in a PyTorch model, a string name for your model and a PyTorch DataLoader instance for the Oxford Pets dataset. In the end, it should take care of the complete model training process for you so that you can focus your energy on how and what to change in your models. (*Hint: as you might have seen in the **Things to consider** section, there are also a few things you can improve over basic the train_model() function to make the training phase a lot more efficient*)\n",
    "\n",
    "In short, we want you to implement the standard deep learning training loop and afterwards expand it how ever you please:\n",
    "- loop over the epochs and batches of input images and labels\n",
    "- calculate the loss of your model predictions\n",
    "- backpropagte the loss\n",
    "- do the optimizer weight update step\n",
    "\n",
    "Additionally, this is where you should utilize the ***CodeCarbon*** benchmarking library, to understand how much time and energy the training phase of your models need.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, model_name:str, train_dataloader:DataLoader, num_epochs, lr):\n",
    "    # You can have a look at the basic implementation of the test_model function to get an idea\n",
    "    \n",
    "    ### Create CodeCarbon tracker object and start the tracker or use the decorator\n",
    "        # Use these configs:\n",
    "            # project_name=\"Model_Training\",\n",
    "            # output_file=\"training_emissions.csv\",\n",
    "            # measure_power_secs=20,\n",
    "            # log_level=\"error\",\n",
    "            # allow_multiple_runs=True\n",
    "    \n",
    "    ### Define a loss function\n",
    "    loss = ...\n",
    "\n",
    "    ### Define an optimizer\n",
    "    optimizer = ...\n",
    "\n",
    "    ### Implement the basic training loop for PyTorch\n",
    "        # Loop over epochs and batches of images and labels\n",
    "            # Get model output\n",
    "            # Calculate loss\n",
    "            # Backpropagate loss\n",
    "            # Optimizer update step\n",
    "\n",
    "    ### Stop CodeCarbon tracker if you did not use the decorator version\n",
    "\n",
    "    ### Store model on disk\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `test_model()` function\n",
    "This function again takes in a PyTorch model and a PyTorch DataLoader instance of the test split of the dataset, calculates the test accuracy and the inference latency and energy usage at test time of your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_dataloader):\n",
    "    # Send model to gpu\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Set model to inference mode\n",
    "    model.eval()\n",
    "\n",
    "    tracker = EmissionsTracker(\n",
    "        project_name=\"Model_Inference\",\n",
    "        output_file=\"inference_emissions.csv\",\n",
    "        measure_power_secs=20,\n",
    "        log_level=\"error\",\n",
    "        allow_multiple_runs=True\n",
    "    )\n",
    "    tracker.start()\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    try:\n",
    "        correct = total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_dataloader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                images, labels = images.to(\"cpu\"), labels.to(\"cpu\")\n",
    "        \n",
    "        total_inference_time = time.perf_counter() - start_time\n",
    "\n",
    "        avg_inference_latency = total_inference_time / len(test_dataloader.dataset)\n",
    "        test_acc = 100 * correct / total\n",
    "        \n",
    "        tracker.stop()\n",
    "        emissions_data = tracker.final_emissions_data\n",
    "\n",
    "        print(f\"[Inference] #Test Samples: {len(test_dataloader.dataset)} | Average Inference Latency: {avg_inference_latency:.4f} seconds | Test Accuracy: {test_acc:.1f}%\") \n",
    "        print(f\"  - CO2 Emissions: {emissions_data.emissions:.6f} kg | Total Energy Usage: {emissions_data.energy_consumed:.7f} kWh\")\n",
    "        return {\n",
    "            \"inference_latency\": avg_inference_latency,\n",
    "            \"test_accuracy\": test_acc,\n",
    "            \"emissions_data\": emissions_data\n",
    "        }\n",
    "\n",
    "    finally:\n",
    "        tracker.stop()\n",
    "        model.to(\"cpu\")\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally create, train and test your models here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "output_size = 37 # Oxford Pets 37 categories\n",
    "\n",
    "# Data set transforms, you can change these how ever you please for your models\n",
    "transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])\n",
    "\n",
    "# Download the train and test sets of the dataset and use your transforms\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "train_dataset = datasets.OxfordIIITPet(root=\"./data\", split=\"trainval\", transform=transforms, download=True)\n",
    "test_dataset = datasets.OxfordIIITPet(root=\"./data\", split=\"test\", transform=transforms, download=True)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create your model\n",
    "    # You can either build one from scratch, or try builtin model architectures from PyTorch (ResNet, MobileNet, ...)\n",
    "    # Best start with a simple model to test the training and testing workflow and then work up to more complex models\n",
    "model = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train your model\n",
    "trained_model = train_model(model, \"YOUR_MODEL_NAME\", train_dataloader)\n",
    "\n",
    "### Test your model\n",
    "test_stats_dict = test_model(trained_model, test_dataloader)\n",
    "\n",
    "\n",
    "# Free up memory \n",
    "trained_model.to(\"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
